A video demostration is on youTube here https://youtu.be/dv1DAupmCto

 * Robot vision on  Raspberry Pi 4 Model B Linux based platform
 * Joint command on  TI MSP430FR5969
 
![robot1](https://user-images.githubusercontent.com/67382222/111897398-09a00280-8a20-11eb-8b5a-8df27075609b.JPG)
![robot2](https://user-images.githubusercontent.com/67382222/111897407-1ae90f00-8a20-11eb-9f4f-488f97be4e83.JPG)
![robot3](https://user-images.githubusercontent.com/67382222/111897413-26d4d100-8a20-11eb-88a0-77cf2339ded5.JPG)

See the website: https://hodoemelem.github.io/ 

The full system and source code description can be found in this attached pdf: 
A_Rapid_Prototyping_Framework_for_Human_Robot_Interaction.pdf

This repository has the source code for our paper accepted for the #UbiComp2020 conference.
Title: A Low-Cost Prototyping Framework for Human-Robot Desk Interaction.
Conference: UbiComp/ISWC 2020 http://ubicomp.org/ubicomp2020/#:~:text=Ubicomp%202020%20will%20be%20multi,on%2012%20-%2013th%20September%202020.

Many current human-robot interactive systems tend to use accurate and fast, but also costly actuators
and tracking systems to establish working prototypes that are safe to use and deploy for user studies.
This work presents an embedded framework to build a desktop space for human-robot interaction, using 
an open-design robot arm, as well as two RGB cameras connected to a Raspberry Pi-based controller that 
allow a fast yet low-cost object tracking and manipulation in 3D. Results show that this facilitates
prototyping a number of systems in which user and robot arm can commonly interact with physical objects.

This work presents a embedded framework for human-robot interaction to allow robotics enthusiasts and researchers
to develop low-cost and rapid prototypes of robot arms, to test out project ideas for educational purposes or before
a full scale implementation. This report will show that the robot arm can autonomously and quickly locate any object(s)
at any position within its workspace, and can perform a specific (different) task depending on the id of the fiducial marker 
identified. Also, early stage development of the embedded framework is introduced and explained, experimental case studies and
performance results are presented. 




